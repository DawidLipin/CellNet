{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from CellNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "dataset2 = datasets.MNIST('../data', train=False,transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=1)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellnum = 4\n",
    "incellnum = 2\n",
    "outcellnum = 1\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellNetMNIST(nn.Module):\n",
    "    def __init__(self, cellnum, incellnum, outcellnum):\n",
    "        super(CellNetMNIST, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        self.cellnum = cellnum\n",
    "        self.incellnum = incellnum\n",
    "        self.outcellnum = outcellnum\n",
    "\n",
    "        self.cells = []\n",
    "        for _ in range(incellnum):\n",
    "            self.cells.append(InCell(64, 64, cellnum-1, 9216))\n",
    "\n",
    "        for _ in range(cellnum - incellnum - outcellnum):\n",
    "            self.cells.append(Cell(64, 64, cellnum-1))\n",
    "\n",
    "        for _ in range(outcellnum):\n",
    "            self.cells.append(OutCell(64, 64, cellnum-1, 10))\n",
    "\n",
    "\n",
    "    def first_step(self, train_loader):\n",
    "\n",
    "        optimizers = []\n",
    "        for cell in self.cells:\n",
    "            optimizers.append(torch.optim.Adam(cell.parameters()))\n",
    "\n",
    "        optimizer_base = torch.optim.Adam([\n",
    "                {'params': self.conv1.parameters()},\n",
    "                {'params': self.conv2.parameters()},\n",
    "                {'params': self.dropout1.parameters()}\n",
    "            ])\n",
    "\n",
    "        initialconn = []\n",
    "        for _ in range(cellnum-1):\n",
    "            initialconn.append(torch.zeros(64))\n",
    "\n",
    "        sample_img, sample_target = next(iter(train_loader))\n",
    "\n",
    "        for cell_optim in optimizers:\n",
    "            cell_optim.zero_grad()\n",
    "\n",
    "        optimizer_base.zero_grad()\n",
    "\n",
    "        x = self.conv1(sample_img)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        # x = torch.flatten(x, 1) # Needes to be fixed to allow for batches\n",
    "        x = torch.flatten(x, 0)\n",
    "\n",
    "        initialouts = []\n",
    "        new_cores = []\n",
    "        for idx, cell in enumerate(self.cells):\n",
    "            if idx < incellnum:\n",
    "                initialout, new_core = cell(initialconn, x)\n",
    "                initialouts.append(initialout)\n",
    "                new_cores.append(new_core)\n",
    "            elif idx >= incellnum and idx < cellnum - outcellnum:\n",
    "                initialout, new_core = cell(initialconn)\n",
    "                initialouts.append(initialout)\n",
    "                new_cores.append(new_core)\n",
    "            else: #works only for outcellnum = 1\n",
    "                initialout, new_core, output = cell(initialconn, out=True)\n",
    "                initialouts.append(initialout)\n",
    "                new_cores.append(new_core)\n",
    "        \n",
    "        output = F.log_softmax(output, dim=0) # dim=1 when batched\n",
    "        loss = F.nll_loss(torch.unsqueeze(output,0), sample_target) # Unsqueeze wont be needed when batched\n",
    "\n",
    "        print(new_cores)\n",
    "\n",
    "        print(self.cells[0].core)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_base.step()\n",
    "\n",
    "        print(self.cells[0].core)\n",
    "\n",
    "        for cell_optim in optimizers:\n",
    "            cell_optim.zero_grad()\n",
    "\n",
    "        # Group new cores by which cell they will be input into\n",
    "        # TODO: Optimise this\n",
    "        initialouts_grouped = [[] for _ in initialouts]\n",
    "        for idx, iniout in enumerate(initialouts):\n",
    "            for grpidx, i in enumerate(iniout):\n",
    "                if grpidx < idx:\n",
    "                    initialouts_grouped[grpidx].append(i)\n",
    "                elif grpidx >= idx:\n",
    "                    initialouts_grouped[grpidx+1].append(i)\n",
    "\n",
    "        return optimizers, optimizer_base, initialouts_grouped, new_cores\n",
    "\n",
    "    def forward(self, prev_conn, prev_cores, x=None):\n",
    "        if x is not None:\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            # x = torch.flatten(x, 1) # Needes to be fixed to allow for batches\n",
    "            x = torch.flatten(x, 0)\n",
    "\n",
    "        new_conns = []\n",
    "        new_cores = []\n",
    "        for idx, cell in enumerate(self.cells):\n",
    "            if idx < incellnum:\n",
    "                new_conn, new_core = cell(prev_conn[idx], x)\n",
    "                new_conns.append(new_conn)\n",
    "                new_cores.append(new_core)\n",
    "            elif idx >= incellnum and idx < cellnum - outcellnum:\n",
    "                new_conn, new_core = cell(prev_conn[idx])\n",
    "                new_conns.append(new_conn)\n",
    "                new_cores.append(new_core)\n",
    "            else: #works only for outcellnum = 1\n",
    "                new_conn, new_core, output = cell(prev_conn[idx], out=True)\n",
    "                new_conns.append(new_conn)\n",
    "                new_cores.append(new_core)\n",
    "\n",
    "        output = F.log_softmax(output, dim=0) # dim=1 when batched\n",
    "\n",
    "        new_conns_grouped = [[] for _ in initialouts]\n",
    "        for idx, iniout in enumerate(initialouts):\n",
    "            for grpidx, i in enumerate(iniout):\n",
    "                if grpidx < idx:\n",
    "                    new_conns_grouped[grpidx].append(i)\n",
    "                elif grpidx >= idx:\n",
    "                    new_conns_grouped[grpidx+1].append(i)\n",
    "        \n",
    "        return output, new_conns_grouped, new_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([-0.1430, -0.1388, -0.2437, -0.0997,  0.1904,  0.1540,  0.0597,  0.0656,\n",
      "         0.1246,  0.1975,  0.2180, -0.1246, -0.3351,  0.0435, -0.1144,  0.2654,\n",
      "         0.0874,  0.0527,  0.1728,  0.0604, -0.0550,  0.1212,  0.0264, -0.2357,\n",
      "         0.3122,  0.0952,  0.3136, -0.1442,  0.0408, -0.1833,  0.1451, -0.1762,\n",
      "        -0.0483, -0.1619,  0.0973, -0.0690, -0.1009, -0.3599,  0.0120, -0.3232,\n",
      "        -0.1335,  0.3842,  0.0113, -0.0067,  0.0260,  0.1846, -0.5403, -0.2982,\n",
      "         0.0487,  0.2373,  0.1381,  0.0897,  0.0401, -0.2979,  0.1204,  0.0130,\n",
      "        -0.2373,  0.2124, -0.2652,  0.1871,  0.0500, -0.1070,  0.0321,  0.3206],\n",
      "       grad_fn=<ViewBackward0>), tensor([-0.1454, -0.1430, -0.2474, -0.0959,  0.1872,  0.1526,  0.0575,  0.0641,\n",
      "         0.1254,  0.1974,  0.2202, -0.1270, -0.3399,  0.0431, -0.1130,  0.2668,\n",
      "         0.0875,  0.0534,  0.1767,  0.0585, -0.0534,  0.1201,  0.0272, -0.2325,\n",
      "         0.3144,  0.0970,  0.3103, -0.1502,  0.0379, -0.1784,  0.1441, -0.1785,\n",
      "        -0.0510, -0.1611,  0.0956, -0.0681, -0.1018, -0.3544,  0.0109, -0.3232,\n",
      "        -0.1339,  0.3877,  0.0078, -0.0070,  0.0280,  0.1838, -0.5429, -0.2983,\n",
      "         0.0514,  0.2401,  0.1380,  0.0881,  0.0396, -0.2939,  0.1206,  0.0141,\n",
      "        -0.2393,  0.2132, -0.2655,  0.1864,  0.0471, -0.1080,  0.0392,  0.3197],\n",
      "       grad_fn=<ViewBackward0>), tensor([-0.1436, -0.1420, -0.2433, -0.0970,  0.1913,  0.1529,  0.0593,  0.0634,\n",
      "         0.1251,  0.1934,  0.2169, -0.1241, -0.3385,  0.0413, -0.1171,  0.2685,\n",
      "         0.0873,  0.0496,  0.1708,  0.0569, -0.0488,  0.1253,  0.0256, -0.2344,\n",
      "         0.3105,  0.0961,  0.3157, -0.1489,  0.0420, -0.1822,  0.1391, -0.1769,\n",
      "        -0.0499, -0.1621,  0.1033, -0.0775, -0.1004, -0.3531,  0.0140, -0.3224,\n",
      "        -0.1388,  0.3828,  0.0107, -0.0089,  0.0291,  0.1830, -0.5420, -0.3039,\n",
      "         0.0470,  0.2340,  0.1399,  0.0873,  0.0389, -0.2950,  0.1238,  0.0107,\n",
      "        -0.2350,  0.2078, -0.2658,  0.1946,  0.0463, -0.1082,  0.0339,  0.3130],\n",
      "       grad_fn=<ViewBackward0>)], [tensor([-0.0393, -0.0819,  0.0918, -0.0635,  0.0981,  0.1578,  0.0645,  0.1803,\n",
      "        -0.1488, -0.2537, -0.1401,  0.0419,  0.0916,  0.0793, -0.1185,  0.0165,\n",
      "         0.1131,  0.1093, -0.0037,  0.0339,  0.1354, -0.0524,  0.3732, -0.0635,\n",
      "        -0.2081, -0.0641,  0.0951,  0.2548,  0.0011, -0.0801,  0.0988,  0.1109,\n",
      "         0.1181, -0.0625, -0.1767, -0.1425, -0.0066,  0.2979,  0.3324,  0.0169,\n",
      "        -0.0712,  0.0322,  0.0194, -0.0638, -0.0625,  0.1369,  0.2413,  0.2475,\n",
      "        -0.1111,  0.2132, -0.0024,  0.0346,  0.0890,  0.1504, -0.0148,  0.2090,\n",
      "        -0.2556,  0.1046,  0.0997,  0.0336,  0.4488, -0.3738,  0.2470, -0.0950],\n",
      "       grad_fn=<ViewBackward0>), tensor([-0.0380, -0.0870,  0.0895, -0.0616,  0.0963,  0.1546,  0.0690,  0.1819,\n",
      "        -0.1496, -0.2525, -0.1387,  0.0427,  0.0950,  0.0816, -0.1206,  0.0188,\n",
      "         0.1127,  0.1142, -0.0041,  0.0371,  0.1305, -0.0495,  0.3716, -0.0658,\n",
      "        -0.2020, -0.0618,  0.0948,  0.2528, -0.0015, -0.0773,  0.0973,  0.1116,\n",
      "         0.1180, -0.0630, -0.1775, -0.1423, -0.0048,  0.2993,  0.3304,  0.0172,\n",
      "        -0.0713,  0.0309,  0.0168, -0.0657, -0.0643,  0.1353,  0.2421,  0.2466,\n",
      "        -0.1121,  0.2110,  0.0009,  0.0362,  0.0908,  0.1539, -0.0164,  0.2084,\n",
      "        -0.2549,  0.1011,  0.1007,  0.0309,  0.4485, -0.3694,  0.2482, -0.0926],\n",
      "       grad_fn=<ViewBackward0>), tensor([-4.2465e-02, -8.7801e-02,  9.1104e-02, -6.1336e-02,  1.0098e-01,\n",
      "         1.5787e-01,  6.5915e-02,  1.7919e-01, -1.4652e-01, -2.5242e-01,\n",
      "        -1.3748e-01,  4.2854e-02,  9.5456e-02,  8.3262e-02, -1.1902e-01,\n",
      "         1.6373e-02,  1.1235e-01,  1.0883e-01, -8.7155e-03,  3.3714e-02,\n",
      "         1.2972e-01, -4.8985e-02,  3.7199e-01, -6.5351e-02, -2.0296e-01,\n",
      "        -6.6136e-02,  9.7559e-02,  2.6074e-01, -2.7482e-04, -8.0558e-02,\n",
      "         1.0058e-01,  1.1226e-01,  1.1995e-01, -6.4883e-02, -1.7691e-01,\n",
      "        -1.4171e-01, -4.9403e-03,  3.0050e-01,  3.2592e-01,  1.7160e-02,\n",
      "        -6.6206e-02,  3.0962e-02,  1.9658e-02, -6.5827e-02, -6.1564e-02,\n",
      "         1.3613e-01,  2.4289e-01,  2.5176e-01, -1.1581e-01,  2.1670e-01,\n",
      "        -2.4299e-03,  3.4472e-02,  8.9765e-02,  1.4518e-01, -1.7702e-02,\n",
      "         2.0726e-01, -2.5595e-01,  1.1170e-01,  1.0541e-01,  2.9990e-02,\n",
      "         4.4933e-01, -3.7896e-01,  2.5118e-01, -9.4875e-02],\n",
      "       grad_fn=<ViewBackward0>)], [tensor([0.0000, 0.1604, 0.1294, 0.0313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0469,\n",
      "        0.1501, 0.1186, 0.0000, 0.0000, 0.0037, 0.0347, 0.0000, 0.0300, 0.0531,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0717, 0.0149, 0.0000, 0.0465, 0.1146,\n",
      "        0.0000, 0.0947, 0.0153, 0.0000, 0.0159, 0.0000, 0.0144, 0.0000, 0.0104,\n",
      "        0.0525, 0.0000, 0.1081, 0.0367, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.1394, 0.0428, 0.0206, 0.0000, 0.0000, 0.0000, 0.0078, 0.0798, 0.0000,\n",
      "        0.0201, 0.0000, 0.0000, 0.1838, 0.0000, 0.0000, 0.0000, 0.1208, 0.0000,\n",
      "        0.0000], grad_fn=<ReluBackward0>), tensor([0.0813, 0.0000, 0.0000, 0.0000, 0.1664, 0.0000, 0.0000, 0.1060, 0.0000,\n",
      "        0.0706, 0.0632, 0.0960, 0.0615, 0.0000, 0.0571, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1223, 0.0362, 0.0306, 0.0273, 0.0009,\n",
      "        0.1130, 0.0028, 0.0000, 0.0000, 0.0000, 0.0818, 0.0697, 0.1015, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0942, 0.0353, 0.0000, 0.0249,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0858, 0.0000, 0.0000,\n",
      "        0.0375, 0.0000, 0.1278, 0.0000, 0.0503, 0.0319, 0.0000, 0.0000, 0.0338,\n",
      "        0.0718], grad_fn=<ReluBackward0>), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0623, 0.0967, 0.0000,\n",
      "        0.0760, 0.0000, 0.0505, 0.0000, 0.0002, 0.0000, 0.0000, 0.0211, 0.0000,\n",
      "        0.0000, 0.0000, 0.0649, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0653,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0356, 0.0000, 0.0992,\n",
      "        0.0773, 0.0967, 0.0000, 0.0205, 0.0000, 0.0700, 0.0000, 0.0141, 0.0000,\n",
      "        0.1334, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0046, 0.0786, 0.0813,\n",
      "        0.0000, 0.0000, 0.0000, 0.0624, 0.0693, 0.0999, 0.0579, 0.0000, 0.0402,\n",
      "        0.0547], grad_fn=<ReluBackward0>)], [tensor([0.0000, 0.0000, 0.0000, 0.0339, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0776, 0.0000, 0.1505, 0.0000, 0.0397,\n",
      "        0.0000, 0.0632, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1234, 0.0000,\n",
      "        0.1096, 0.0208, 0.0000, 0.0000, 0.0914, 0.0000, 0.0214, 0.0563, 0.0000,\n",
      "        0.0000, 0.0205, 0.0000, 0.0552, 0.1405, 0.0030, 0.0200, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0335, 0.1010, 0.0655, 0.1563, 0.0570, 0.1099,\n",
      "        0.0905, 0.0782, 0.1262, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0012], grad_fn=<ReluBackward0>), tensor([0.0288, 0.0000, 0.0829, 0.0000, 0.0501, 0.1382, 0.0309, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0007, 0.0705, 0.0000, 0.0354, 0.1565, 0.0301,\n",
      "        0.0000, 0.1069, 0.0000, 0.0000, 0.0000, 0.0469, 0.0334, 0.0000, 0.1083,\n",
      "        0.0792, 0.1307, 0.0000, 0.0291, 0.0000, 0.0000, 0.0000, 0.0000, 0.0772,\n",
      "        0.0000, 0.0951, 0.0000, 0.1243, 0.0988, 0.0000, 0.0000, 0.0963, 0.0000,\n",
      "        0.0156, 0.0000, 0.0692, 0.0826, 0.0000, 0.0000, 0.0608, 0.0920, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0412, 0.0948, 0.0195, 0.0000, 0.0000,\n",
      "        0.0530], grad_fn=<ReluBackward0>), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0743, 0.0000, 0.0438, 0.0000, 0.0000,\n",
      "        0.1124, 0.0143, 0.0000, 0.1161, 0.0000, 0.0000, 0.0000, 0.0000, 0.0704,\n",
      "        0.0520, 0.0000, 0.1148, 0.0000, 0.0000, 0.0550, 0.0000, 0.0000, 0.0038,\n",
      "        0.0254, 0.0000, 0.0309, 0.0273, 0.0263, 0.0031, 0.1542, 0.0065, 0.1279,\n",
      "        0.0000, 0.0000, 0.0565, 0.0000, 0.0048, 0.1154, 0.1728, 0.0368, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0582, 0.0253, 0.0000, 0.0532, 0.0333, 0.0304,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0288, 0.0000, 0.0000, 0.0449,\n",
      "        0.0000], grad_fn=<ReluBackward0>)]]\n",
      "[[tensor([-0.0393, -0.0819,  0.0918, -0.0635,  0.0981,  0.1578,  0.0645,  0.1803,\n",
      "        -0.1488, -0.2537, -0.1401,  0.0419,  0.0916,  0.0793, -0.1185,  0.0165,\n",
      "         0.1131,  0.1093, -0.0037,  0.0339,  0.1354, -0.0524,  0.3732, -0.0635,\n",
      "        -0.2081, -0.0641,  0.0951,  0.2548,  0.0011, -0.0801,  0.0988,  0.1109,\n",
      "         0.1181, -0.0625, -0.1767, -0.1425, -0.0066,  0.2979,  0.3324,  0.0169,\n",
      "        -0.0712,  0.0322,  0.0194, -0.0638, -0.0625,  0.1369,  0.2413,  0.2475,\n",
      "        -0.1111,  0.2132, -0.0024,  0.0346,  0.0890,  0.1504, -0.0148,  0.2090,\n",
      "        -0.2556,  0.1046,  0.0997,  0.0336,  0.4488, -0.3738,  0.2470, -0.0950],\n",
      "       grad_fn=<ViewBackward0>), tensor([0.0000, 0.1604, 0.1294, 0.0313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0469,\n",
      "        0.1501, 0.1186, 0.0000, 0.0000, 0.0037, 0.0347, 0.0000, 0.0300, 0.0531,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0717, 0.0149, 0.0000, 0.0465, 0.1146,\n",
      "        0.0000, 0.0947, 0.0153, 0.0000, 0.0159, 0.0000, 0.0144, 0.0000, 0.0104,\n",
      "        0.0525, 0.0000, 0.1081, 0.0367, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.1394, 0.0428, 0.0206, 0.0000, 0.0000, 0.0000, 0.0078, 0.0798, 0.0000,\n",
      "        0.0201, 0.0000, 0.0000, 0.1838, 0.0000, 0.0000, 0.0000, 0.1208, 0.0000,\n",
      "        0.0000], grad_fn=<ReluBackward0>), tensor([0.0000, 0.0000, 0.0000, 0.0339, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0776, 0.0000, 0.1505, 0.0000, 0.0397,\n",
      "        0.0000, 0.0632, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1234, 0.0000,\n",
      "        0.1096, 0.0208, 0.0000, 0.0000, 0.0914, 0.0000, 0.0214, 0.0563, 0.0000,\n",
      "        0.0000, 0.0205, 0.0000, 0.0552, 0.1405, 0.0030, 0.0200, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0335, 0.1010, 0.0655, 0.1563, 0.0570, 0.1099,\n",
      "        0.0905, 0.0782, 0.1262, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0012], grad_fn=<ReluBackward0>)], [tensor([-0.1430, -0.1388, -0.2437, -0.0997,  0.1904,  0.1540,  0.0597,  0.0656,\n",
      "         0.1246,  0.1975,  0.2180, -0.1246, -0.3351,  0.0435, -0.1144,  0.2654,\n",
      "         0.0874,  0.0527,  0.1728,  0.0604, -0.0550,  0.1212,  0.0264, -0.2357,\n",
      "         0.3122,  0.0952,  0.3136, -0.1442,  0.0408, -0.1833,  0.1451, -0.1762,\n",
      "        -0.0483, -0.1619,  0.0973, -0.0690, -0.1009, -0.3599,  0.0120, -0.3232,\n",
      "        -0.1335,  0.3842,  0.0113, -0.0067,  0.0260,  0.1846, -0.5403, -0.2982,\n",
      "         0.0487,  0.2373,  0.1381,  0.0897,  0.0401, -0.2979,  0.1204,  0.0130,\n",
      "        -0.2373,  0.2124, -0.2652,  0.1871,  0.0500, -0.1070,  0.0321,  0.3206],\n",
      "       grad_fn=<ViewBackward0>), tensor([0.0813, 0.0000, 0.0000, 0.0000, 0.1664, 0.0000, 0.0000, 0.1060, 0.0000,\n",
      "        0.0706, 0.0632, 0.0960, 0.0615, 0.0000, 0.0571, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1223, 0.0362, 0.0306, 0.0273, 0.0009,\n",
      "        0.1130, 0.0028, 0.0000, 0.0000, 0.0000, 0.0818, 0.0697, 0.1015, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0942, 0.0353, 0.0000, 0.0249,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0858, 0.0000, 0.0000,\n",
      "        0.0375, 0.0000, 0.1278, 0.0000, 0.0503, 0.0319, 0.0000, 0.0000, 0.0338,\n",
      "        0.0718], grad_fn=<ReluBackward0>), tensor([0.0288, 0.0000, 0.0829, 0.0000, 0.0501, 0.1382, 0.0309, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0007, 0.0705, 0.0000, 0.0354, 0.1565, 0.0301,\n",
      "        0.0000, 0.1069, 0.0000, 0.0000, 0.0000, 0.0469, 0.0334, 0.0000, 0.1083,\n",
      "        0.0792, 0.1307, 0.0000, 0.0291, 0.0000, 0.0000, 0.0000, 0.0000, 0.0772,\n",
      "        0.0000, 0.0951, 0.0000, 0.1243, 0.0988, 0.0000, 0.0000, 0.0963, 0.0000,\n",
      "        0.0156, 0.0000, 0.0692, 0.0826, 0.0000, 0.0000, 0.0608, 0.0920, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0412, 0.0948, 0.0195, 0.0000, 0.0000,\n",
      "        0.0530], grad_fn=<ReluBackward0>)], [tensor([-0.1454, -0.1430, -0.2474, -0.0959,  0.1872,  0.1526,  0.0575,  0.0641,\n",
      "         0.1254,  0.1974,  0.2202, -0.1270, -0.3399,  0.0431, -0.1130,  0.2668,\n",
      "         0.0875,  0.0534,  0.1767,  0.0585, -0.0534,  0.1201,  0.0272, -0.2325,\n",
      "         0.3144,  0.0970,  0.3103, -0.1502,  0.0379, -0.1784,  0.1441, -0.1785,\n",
      "        -0.0510, -0.1611,  0.0956, -0.0681, -0.1018, -0.3544,  0.0109, -0.3232,\n",
      "        -0.1339,  0.3877,  0.0078, -0.0070,  0.0280,  0.1838, -0.5429, -0.2983,\n",
      "         0.0514,  0.2401,  0.1380,  0.0881,  0.0396, -0.2939,  0.1206,  0.0141,\n",
      "        -0.2393,  0.2132, -0.2655,  0.1864,  0.0471, -0.1080,  0.0392,  0.3197],\n",
      "       grad_fn=<ViewBackward0>), tensor([-0.0380, -0.0870,  0.0895, -0.0616,  0.0963,  0.1546,  0.0690,  0.1819,\n",
      "        -0.1496, -0.2525, -0.1387,  0.0427,  0.0950,  0.0816, -0.1206,  0.0188,\n",
      "         0.1127,  0.1142, -0.0041,  0.0371,  0.1305, -0.0495,  0.3716, -0.0658,\n",
      "        -0.2020, -0.0618,  0.0948,  0.2528, -0.0015, -0.0773,  0.0973,  0.1116,\n",
      "         0.1180, -0.0630, -0.1775, -0.1423, -0.0048,  0.2993,  0.3304,  0.0172,\n",
      "        -0.0713,  0.0309,  0.0168, -0.0657, -0.0643,  0.1353,  0.2421,  0.2466,\n",
      "        -0.1121,  0.2110,  0.0009,  0.0362,  0.0908,  0.1539, -0.0164,  0.2084,\n",
      "        -0.2549,  0.1011,  0.1007,  0.0309,  0.4485, -0.3694,  0.2482, -0.0926],\n",
      "       grad_fn=<ViewBackward0>), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0743, 0.0000, 0.0438, 0.0000, 0.0000,\n",
      "        0.1124, 0.0143, 0.0000, 0.1161, 0.0000, 0.0000, 0.0000, 0.0000, 0.0704,\n",
      "        0.0520, 0.0000, 0.1148, 0.0000, 0.0000, 0.0550, 0.0000, 0.0000, 0.0038,\n",
      "        0.0254, 0.0000, 0.0309, 0.0273, 0.0263, 0.0031, 0.1542, 0.0065, 0.1279,\n",
      "        0.0000, 0.0000, 0.0565, 0.0000, 0.0048, 0.1154, 0.1728, 0.0368, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0582, 0.0253, 0.0000, 0.0532, 0.0333, 0.0304,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0288, 0.0000, 0.0000, 0.0449,\n",
      "        0.0000], grad_fn=<ReluBackward0>)], [tensor([-0.1436, -0.1420, -0.2433, -0.0970,  0.1913,  0.1529,  0.0593,  0.0634,\n",
      "         0.1251,  0.1934,  0.2169, -0.1241, -0.3385,  0.0413, -0.1171,  0.2685,\n",
      "         0.0873,  0.0496,  0.1708,  0.0569, -0.0488,  0.1253,  0.0256, -0.2344,\n",
      "         0.3105,  0.0961,  0.3157, -0.1489,  0.0420, -0.1822,  0.1391, -0.1769,\n",
      "        -0.0499, -0.1621,  0.1033, -0.0775, -0.1004, -0.3531,  0.0140, -0.3224,\n",
      "        -0.1388,  0.3828,  0.0107, -0.0089,  0.0291,  0.1830, -0.5420, -0.3039,\n",
      "         0.0470,  0.2340,  0.1399,  0.0873,  0.0389, -0.2950,  0.1238,  0.0107,\n",
      "        -0.2350,  0.2078, -0.2658,  0.1946,  0.0463, -0.1082,  0.0339,  0.3130],\n",
      "       grad_fn=<ViewBackward0>), tensor([-4.2465e-02, -8.7801e-02,  9.1104e-02, -6.1336e-02,  1.0098e-01,\n",
      "         1.5787e-01,  6.5915e-02,  1.7919e-01, -1.4652e-01, -2.5242e-01,\n",
      "        -1.3748e-01,  4.2854e-02,  9.5456e-02,  8.3262e-02, -1.1902e-01,\n",
      "         1.6373e-02,  1.1235e-01,  1.0883e-01, -8.7155e-03,  3.3714e-02,\n",
      "         1.2972e-01, -4.8985e-02,  3.7199e-01, -6.5351e-02, -2.0296e-01,\n",
      "        -6.6136e-02,  9.7559e-02,  2.6074e-01, -2.7482e-04, -8.0558e-02,\n",
      "         1.0058e-01,  1.1226e-01,  1.1995e-01, -6.4883e-02, -1.7691e-01,\n",
      "        -1.4171e-01, -4.9403e-03,  3.0050e-01,  3.2592e-01,  1.7160e-02,\n",
      "        -6.6206e-02,  3.0962e-02,  1.9658e-02, -6.5827e-02, -6.1564e-02,\n",
      "         1.3613e-01,  2.4289e-01,  2.5176e-01, -1.1581e-01,  2.1670e-01,\n",
      "        -2.4299e-03,  3.4472e-02,  8.9765e-02,  1.4518e-01, -1.7702e-02,\n",
      "         2.0726e-01, -2.5595e-01,  1.1170e-01,  1.0541e-01,  2.9990e-02,\n",
      "         4.4933e-01, -3.7896e-01,  2.5118e-01, -9.4875e-02],\n",
      "       grad_fn=<ViewBackward0>), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0623, 0.0967, 0.0000,\n",
      "        0.0760, 0.0000, 0.0505, 0.0000, 0.0002, 0.0000, 0.0000, 0.0211, 0.0000,\n",
      "        0.0000, 0.0000, 0.0649, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0653,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0356, 0.0000, 0.0992,\n",
      "        0.0773, 0.0967, 0.0000, 0.0205, 0.0000, 0.0700, 0.0000, 0.0141, 0.0000,\n",
      "        0.1334, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0046, 0.0786, 0.0813,\n",
      "        0.0000, 0.0000, 0.0000, 0.0624, 0.0693, 0.0999, 0.0579, 0.0000, 0.0402,\n",
      "        0.0547], grad_fn=<ReluBackward0>)]]\n"
     ]
    }
   ],
   "source": [
    "model = CellNetMNIST(cellnum, incellnum, outcellnum)\n",
    "\n",
    "_ = model.first_step(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555530"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CellNetMNIST(cellnum, incellnum, outcellnum)\n",
    "def get_n_params_cell(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    for cell in model.cells:\n",
    "        for p in list(cell.parameters()):\n",
    "            nn=1\n",
    "            for s in list(p.size()):\n",
    "                nn = nn*s\n",
    "            pp += nn\n",
    "    return pp\n",
    "\n",
    "get_n_params_cell(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CellNetMNIST(cellnum, incellnum, outcellnum)\n",
    "\n",
    "optimizers, optimizer_base, initialouts = model.first_step(train_loader)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for idx, imgs in enumerate(images):\n",
    "\n",
    "        \n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OmniNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
